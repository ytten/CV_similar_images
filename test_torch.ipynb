{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler, random_split\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torch.nn import SyncBatchNorm\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToPILImage\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "target_shape = (200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of left images: 2000\n",
      "\n",
      "Number of right images: 2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getImagePaths(path):\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names\n",
    "\n",
    "left_dir_path = \"ImgData/train/left\"\n",
    "right_dir_path = \"ImgData/train/right\"\n",
    "\n",
    "left_images_path = getImagePaths(left_dir_path)\n",
    "right_images_path = getImagePaths(right_dir_path)\n",
    "\n",
    "print(f\"Number of left images: {len(left_images_path)}\\n\")\n",
    "print(f\"Number of right images: {len(right_images_path)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getShape(images_paths):\n",
    "    shape = cv2.imread(images_paths[0]).shape\n",
    "    for image_path in images_paths:\n",
    "        image_shape=cv2.imread(image_path).shape\n",
    "        if (image_shape!=shape):\n",
    "            return \"Different image shape\"\n",
    "        else:\n",
    "            return \"Same image shape \" + str(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_images_path = sorted(left_images_path, key=lambda x: x.split('/')[-1])\n",
    "right_images_path = sorted(right_images_path, key=lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images = left_images_path\n",
    "positive_images = right_images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_tensor):\n",
    "    \"\"\"\n",
    "    Preprocess the input image tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the transformations: resize\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize(target_shape, antialias=True),  # Explicitly set antialias to True\n",
    "    ])\n",
    "    \n",
    "    # Apply the transformations\n",
    "    image = transform(image_tensor)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def preprocess_triplets(anchor, positive, negative):\n",
    "    \"\"\"\n",
    "    Given the filenames corresponding to the three images, load and\n",
    "    preprocess them.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        preprocess_image(anchor),\n",
    "        preprocess_image(positive),\n",
    "        preprocess_image(negative),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLLDataset(Dataset):\n",
    "    def __init__(self, anchor_image_paths, positive_image_paths):\n",
    "        # Load images and convert to tensors\n",
    "        anchor_images = [read_image(path) for path in anchor_image_paths]\n",
    "        positive_images = [read_image(path) for path in positive_image_paths]\n",
    "        \n",
    "        # Shuffle anchor and positive images to get negative images\n",
    "        negative_images = anchor_images + positive_images\n",
    "        random.shuffle(negative_images)\n",
    "        \n",
    "        self.anchor_images = torch.stack(anchor_images)\n",
    "        self.positive_images = torch.stack(positive_images)\n",
    "        self.negative_images = torch.stack(negative_images)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.anchor_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.anchor_images[idx]\n",
    "        positive = self.positive_images[idx]\n",
    "        negative = self.negative_images[idx]\n",
    "        \n",
    "        # Assuming preprocess_triplets is a function you have defined elsewhere\n",
    "        anchor, positive, negative = preprocess_triplets(anchor, positive, negative)\n",
    "        \n",
    "        return anchor, positive, negative\n",
    "\n",
    "\n",
    "# Create an instance of TLLDataset\n",
    "tll_dataset = TLLDataset(anchor_images, positive_images)\n",
    "\n",
    "# Determine the indices for training and validation\n",
    "image_count = len(tll_dataset)\n",
    "indices = list(range(image_count))\n",
    "train_indices = indices[:round(image_count * 0.8)]\n",
    "val_indices = indices[round(image_count * 0.8):]\n",
    "\n",
    "# Create SubsetRandomSamplers\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_loader = DataLoader(tll_dataset, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(tll_dataset, batch_size=32, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 31932, 68844, 71604, 66748, 22652, 22416, 35040, 67148) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\ty\\CV_similar_images\\test_torch.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         show(axs[i, \u001b[39m2\u001b[39m], negative[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Assuming train_loader is the PyTorch DataLoader for training data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Get one batch of data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m anchor, positive, negative \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     visualize(anchor, positive, negative)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# visualize only one batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 31932, 68844, 71604, 66748, 22652, 22416, 35040, 67148) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "def visualize(anchor, positive, negative):\n",
    "    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
    "    \n",
    "    def show(ax, image_tensor):\n",
    "        # Define a transform to convert a tensor to PIL image\n",
    "        transform = transforms.ToPILImage()\n",
    "        # Convert the tensor to PIL image using the above transform\n",
    "        img = transform(image_tensor)\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(9, 9))\n",
    "\n",
    "    for i in range(3):\n",
    "        show(axs[i, 0], anchor[i])\n",
    "        show(axs[i, 1], positive[i])\n",
    "        show(axs[i, 2], negative[i])\n",
    "\n",
    "# Assuming train_loader is the PyTorch DataLoader for training data\n",
    "# Get one batch of data\n",
    "for anchor, positive, negative in train_loader:\n",
    "    visualize(anchor, positive, negative)\n",
    "    break  # visualize only one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        # Load a pre-trained ResNet50 model\n",
    "        resnet = resnet50()\n",
    "        # Freeze all layers except the last Convolution block\n",
    "        for name, param in resnet.named_parameters():\n",
    "            if \"layer4\" not in name:\n",
    "                param.requires_grad = False\n",
    "        # Define the embedding network by adding a few dense layers\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])  # Exclude the last FC layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Sequential(nn.Linear(2048, 512), nn.ReLU(), SyncBatchNorm(512))\n",
    "        self.dense2 = nn.Sequential(nn.Linear(512, 256), nn.ReLU(), SyncBatchNorm(256))\n",
    "        self.output = nn.Linear(256, 256)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "embedding_net = EmbeddingNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistanceLayer, self).__init__()\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        ap_distance = F.pairwise_distance(anchor, positive, 2)\n",
    "        an_distance = F.pairwise_distance(anchor, negative, 2)\n",
    "        return ap_distance, an_distance\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "        self.distance_layer = DistanceLayer()\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        anchor_embedding = self.embedding_net(anchor)\n",
    "        positive_embedding = self.embedding_net(positive)\n",
    "        negative_embedding = self.embedding_net(negative)\n",
    "        ap_distance, an_distance = self.distance_layer(anchor_embedding, positive_embedding, negative_embedding)\n",
    "        return ap_distance, an_distance\n",
    "\n",
    "siamese_network = SiameseNetwork(embedding_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletMarginLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(TripletMarginLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, ap_distance, an_distance):\n",
    "        return F.relu(ap_distance - an_distance + self.margin)\n",
    "\n",
    "class SiameseModel:\n",
    "    def __init__(self, siamese_network, device, margin=0.5, lr=1e-4):\n",
    "        self.siamese_network = siamese_network\n",
    "        self.criterion = TripletMarginLoss(margin)\n",
    "        self.optimizer = torch.optim.Adam(self.siamese_network.parameters(), lr=lr)\n",
    "        self.device = device\n",
    "        self.loss_tracker = []\n",
    "        self.test_loss_tracker = []\n",
    "        \n",
    "    def train_step(self, anchor, positive, negative):\n",
    "        self.siamese_network.train()  # Set the model to training mode\n",
    "        self.optimizer.zero_grad()\n",
    "        ap_distance, an_distance = self.siamese_network(anchor, positive, negative)\n",
    "        loss = self.criterion(ap_distance, an_distance)\n",
    "\n",
    "        # Ensure the loss is a scalar\n",
    "        if loss.numel() > 1:\n",
    "            loss = loss.mean()  # or loss.sum(), depending on your use case\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.loss_tracker.append(loss.item())\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def test_step(self, anchor, positive, negative):\n",
    "        self.siamese_network.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            ap_distance, an_distance = self.siamese_network(anchor, positive, negative)\n",
    "            loss = self.criterion(ap_distance, an_distance)\n",
    "\n",
    "            # Ensure the loss is a scalar\n",
    "            if loss.numel() > 1:\n",
    "                loss = loss.mean()  # or loss.sum(), depending on your use case\n",
    "\n",
    "        self.test_loss_tracker.append(loss.item())\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def train_epoch(self, train_loader):\n",
    "        epoch_loss = 0.0\n",
    "        for anchor,positive,negative in train_loader:\n",
    "            anchor = anchor.to(self.device, dtype=torch.float)\n",
    "            positive = positive.to(self.device, dtype=torch.float)\n",
    "            negative = negative.to(self.device, dtype=torch.float)\n",
    "            \n",
    "            loss = self.train_step(anchor, positive, negative)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss / len(train_loader)\n",
    "\n",
    "    def test_epoch(self, test_loader):\n",
    "        epoch_loss = 0.0\n",
    "        for anchor,positive,negative in test_loader:\n",
    "            anchor = anchor.to(self.device, dtype=torch.float)\n",
    "            positive = positive.to(self.device, dtype=torch.float)\n",
    "            negative = negative.to(self.device, dtype=torch.float)\n",
    "            \n",
    "            loss = self.test_step(anchor, positive, negative)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss / len(test_loader)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.loss_tracker = []\n",
    "        self.test_loss_tracker = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 51356, 41748, 66940, 71572, 4408, 70332, 63352, 57928) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\ty\\CV_similar_images\\test_torch.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m siamese_model\u001b[39m.\u001b[39;49mtrain_epoch(train_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     val_loss \u001b[39m=\u001b[39m siamese_model\u001b[39m.\u001b[39mtest_epoch(val_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Validation Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\ty\\CV_similar_images\\test_torch.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_epoch\u001b[39m(\u001b[39mself\u001b[39m, train_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     epoch_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mfor\u001b[39;00m anchor,positive,negative \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         anchor \u001b[39m=\u001b[39m anchor\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ty/CV_similar_images/test_torch.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         positive \u001b[39m=\u001b[39m positive\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 51356, 41748, 66940, 71572, 4408, 70332, 63352, 57928) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Define the device and move the network to the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "siamese_network = siamese_network.to(device)\n",
    "\n",
    "# Now, instantiate the SiameseModel with the siamese_network\n",
    "siamese_model = SiameseModel(siamese_network, device, margin=0.5, lr=0.0001)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = siamese_model.train_epoch(train_loader)\n",
    "    val_loss = siamese_model.test_epoch(val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "    siamese_model.reset_states()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for anchor, positive, negative in train_loader:\n",
    "    visualize(anchor, positive, negative)\n",
    "    break  # visualize only one batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
